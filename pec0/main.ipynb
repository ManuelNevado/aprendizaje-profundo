{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c07b1a8a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "221a7b8a",
   "metadata": {},
   "source": [
    "# PEC0 - Manuel Nevado Fabián"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b04797",
   "metadata": {},
   "source": [
    "### Enunciado\n",
    "Train a deep MLP on the MNIST dataset (you can load it using tf.keras.​data⁠sets.mnist.load_data()). See if you can get over 98% accuracy by manually tuning the hyperparameters. Try searching for the optimal learning rate by using the approach presented in this chapter (i.e., by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up). Next, try tuning the hyperparameters using Keras Tuner with all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard.\n",
    "\n",
    "Este ejercicio aparece resuelto en el github por lo cual vamos a perdir que se realicen las siguientes modificaciones respecto a lo que se indica en el libro:\n",
    "\n",
    "1) Hay que construir redes con al menos 3 y 4 capas ocultas.\n",
    "2) Tanto para la red de 3 como para la de 4 capas ocultas hay que crear dos versiones con diferentes números de neuronas en las capas ocultas y comparar los resultados. Aquí se utilizará el factor de LearningRate que se utiliza en el notebook del libro.\n",
    "3) Para las redes con 3 y 4 capas que hayan obtenido los mejores resultados en el apartado anterior cambiar el factor de LearningRate y comparar los resultados con los obtenidos en el apartado 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bcc3d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 20:07:25.819090: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-03 20:07:25.858187: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-03 20:07:26.750706: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd43c9c",
   "metadata": {},
   "source": [
    "Lo primero es descargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf1d62f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc54b6",
   "metadata": {},
   "source": [
    "Aqui lo que se va a ahcer es de las 60000 images totales se seleccionan las 5000 primeras para validacion y las demas se dejan de entreanmiento. Tambien se convierte los colores de los pixeles de enteros a flotantes para acotarlos entre 0 y 1 y que se procesen mas facilmente por las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd30b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801de172",
   "metadata": {},
   "source": [
    "Aqui lo que vamos a hacer es encontrar la tasa de aprendizaje optima para este problema de regresion, a su vez, lo que vamos a hacer es guardar el valor de la funcion de perdida por cada epoca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876c6157",
   "metadata": {},
   "source": [
    "Aqui lo que se hace es settear la semilla para que el experimento sea reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53459219",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9fff51",
   "metadata": {},
   "source": [
    "Creamos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04109493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/uned/.venv/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764788847.538565   18654 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1764788847.543559   18654 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "models_list = list()\n",
    "\n",
    "model_3_A = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "models_list.append(model_3_A)\n",
    "\n",
    "model_3_B = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(250, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(80, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "models_list.append(model_3_B)\n",
    "\n",
    "model_4_A = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(350, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(275, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "models_list.append(model_4_A)\n",
    "\n",
    "model_4_B = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(400, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(200, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "models_list.append(model_4_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9e882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 258/1719\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.9983 - loss: 0.0063"
     ]
    }
   ],
   "source": [
    "for model in models_list:\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=3e-1)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "    run_index = 1 # increment this at every run\n",
    "    run_logdir = Path() / f\"{model.name}_my_mnist_logs\" / \"run_{:03d}\".format(run_index)\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_mnist_model.keras\", save_best_only=True)\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=100,\n",
    "                        validation_data=(X_valid, y_valid),\n",
    "                        callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])\n",
    "    model = tf.keras.models.load_model(\"my_mnist_model.keras\") # rollback to best model\n",
    "    model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db184356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b47070e3def6b748\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b47070e3def6b748\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_mnist_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502769d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
